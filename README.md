**Dajubhai MiniMart Analysis**

# üìä ITS69304 Individual Assignment ‚Äî Suprem Khatri

This repository contains the **Jupyter Notebook** for dajubhai minimart analysis. The notebook demonstrates a full data science workflow: from data cleaning to model building using a dataset named `DajuBhaiMinimart.csv`.

---

## üìÇ Files
- `ITS69304_SupremKhatri_Individual_Assignment.ipynb` ‚Äî Main notebook with code and analysis.
- `DajuBhaiMinimart.csv` ‚Äî Dataset (assumed provided externally).

---

## üìù Notebook Overview

### 1Ô∏è‚É£ **Importing Libraries**
The following libraries are used:
```python
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")
import plotly.io as pio
pio.renderers.default = 'notebook'
```

---

### 2Ô∏è‚É£ **Data Loading**
```python
df = pd.read_csv('DajuBhaiMinimart.csv')
df.head()
```
- Reads and displays initial data.

---

### 3Ô∏è‚É£ **Data Cleaning**
- Checks data info:
  ```python
  df.info()
  ```
- Checks for missing values:
  ```python
  df.isnull().sum()
  ```
- Drops unnecessary columns:
  ```python
  df.drop('CustomerID', axis=1, inplace=True)
  ```
- Renames columns where necessary.

---

### 4Ô∏è‚É£ **Data Visualization**
- Uses **Seaborn** and **Plotly** to visualize relationships and distributions.
- Example plots:
  ```python
  sns.countplot(x='ProductCategory', data=df)
  px.histogram(df, x='Sales', color='ProductCategory')
  ```

---

### 5Ô∏è‚É£ **Feature Engineering**
- Creates or modifies features to improve model input.
- Handles categorical encoding, scaling, etc.

---

### 6Ô∏è‚É£ **Model Training**
- Trains models such as:
  - Gradient Boosting Regressor
- Example code:
  ```python
  from sklearn.ensemble import GradientBoostingRegressor
  model = GradientBoostingRegressor()
  model.fit(X_train, y_train)
  ```

---

### 7Ô∏è‚É£ **Hyperparameter Tuning & Cross-Validation**
- Performs grid search / cross-validation:
  ```python
  from sklearn.model_selection import GridSearchCV
  params = {'n_estimators': [100, 200], 'learning_rate': [0.1, 0.05]}
  grid = GridSearchCV(GradientBoostingRegressor(), params, cv=5)
  grid.fit(X_train, y_train)
  ```

---

## üöÄ How to Run

‚úÖ Clone or download this repository.

‚úÖ Install requirements:
```bash
pip install pandas matplotlib seaborn plotly scikit-learn
```

‚úÖ Run the notebook:
```bash
jupyter notebook ITS69304_SupremKhatri_Individual_Assignment.ipynb
```

---

## ‚ö†Ô∏è Notes

- Ensure `DajuBhaiMinimart.csv` is present in the notebook directory.
- All visualizations are rendered using Plotly + Seaborn + Matplotlib.
- The notebook suppresses warnings for cleaner output.
---

## üí° Future Work
- Extend analysis with additional models (e.g. XGBoost, Random Forest).
- Improve feature engineering with domain knowledge.
- Deploy model via Flask / Streamlit for interactive use.
